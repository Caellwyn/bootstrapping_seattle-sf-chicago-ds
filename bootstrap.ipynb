{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling with vs. without Replacement\n",
    "\n",
    "Many questions of probability and statistics have to do with sampling from a population. Sometimes it is appropriate to imagine that the initial population is reset after each draw, and sometimes it is not.\n",
    "\n",
    "Here's a case of the former: I go around interviewing people and I record their birthdays.\n",
    "\n",
    "Clearly, two people can have the same birthday, and so I need each birthday to be available for every draw (i.e. interview). This is sampling **with replacement**. (One might even imagine that I interview some people more than once (by random chance).) Note in particular that draws in this context are mutually **independent**.\n",
    "\n",
    "Here's a case of the latter: I am dealt thirteen cards to make a bridge hand. I can't have the same card appear twice in a single hand, so if I am thinking about the statistics of bridge hands, then I'm thinking about sampling **without replacement**.\n",
    "\n",
    "Clearly this difference has an effect on correct calculation.\n",
    "\n",
    "Consider these two similar cases:\n",
    "\n",
    "**Case 1**: We're playing war. Each of us has a deck of cards, and we each turn over one card at a time, the player with the higher card collecting both. A tie in rank triggers \"war\", where more cards are laid down and then another contest is initiated on top of the now larger \"pot\" of cards.\n",
    "\n",
    "Question: What are the chances that you and I turn over cards with the same rank on one round of war?\n",
    "\n",
    "Answer: This is effectively a problem of cards drawn *with replacement*: I can just model this with two draws from a single deck. And so I calculate as follows:\n",
    "\n",
    "I can draw any card first, so that's 52/52. The second card must match the first in rank, so that's 4/52. Thus the chances are $\\frac{52}{52}\\times\\frac{4}{52} = \\frac{1}{13}$.\n",
    "\n",
    "**Case 2**: I am dealt a two-card blackjack hand from a single deck. (Good luck finding this game in Las Vegas!)\n",
    "\n",
    "Question: What are the chances that I am dealt a pair?\n",
    "\n",
    "Answer: The two events, one for each card being passed my way, are *not independent*. What the second card is likely to be is affected by what the first card is. For example, if the first card dealt me is the ace of spades, then there is now zero chance that the second card dealt me will be the ace of spades. (Whereas, if the first card is something else, then the chance that the second card be the ace of spades is greater than 0.) And so this is a problem of cards drawn *without replacement*.\n",
    "\n",
    "So I calculate as follows:\n",
    "\n",
    "I can draw any card first, so that's 52/52. The second card must match the first in rank, so that's 3/51. There are three left of whatever rank matches my first card, and 51 total cards left. Thus the chances are $\\frac{52}{52}\\times\\frac{3}{51} = \\frac{1}{17}$.\n",
    "\n",
    "Bootstrapping is a sort of sampling ***with replacement***.\n",
    "\n",
    "I can effect both sorts of sampling with the `choice()` function inside NumPy's `random` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['red', 'green', 'blue']\n",
    "np.random.choice(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the defaults of this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from an Unknown Distribution\n",
    "\n",
    "Bootstrapping is used when the shape of the population's distribution is unknown. To simulate this situation, let's make several distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = stats.norm(loc=10, scale=5)\n",
    "expon = stats.expon(loc=5, scale=5)\n",
    "uni = stats.uniform(loc=5, scale=10)\n",
    "\n",
    "dists = [norm, expon, uni]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these distributions all have the same mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.mean() == expon.mean() == uni.mean() == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dists(dists, n=100):\n",
    "    \"\"\"Plot histograms of the distributions in dists.\"\"\"\n",
    "    fig, axs = plt.subplots(1, len(dists), figsize=(5*len(dists), 5))\n",
    "    for ax, dist in zip(axs, dists):\n",
    "        ax.hist(dist.rvs(10000))\n",
    "        ax.set_xlim(0, 30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dists(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a distribution at random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.random.choice(dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a million points from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = dist.rvs(10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a sample of 1000 from that million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(pop, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample mean, $\\bar{x}$, is *near* the population mean, $\\mu$, but there's a certain gap between them.\n",
    "\n",
    "## The Algorithm in Words\n",
    "\n",
    "What we want to do now is what we just did, but *many* times. We can record statistics about each sample, and **then** do statistics on those statistics!\n",
    "\n",
    "The idea is that statistics on this collection of samples, each made **with replacement**, will be a good approximation of the population parameters from which our original sample was drawn. And the more samples we take, the better our approximation should be. In this way we are \"pulling ourselves up by our own bootstraps\" to make inferences about the population as a whole.\n",
    "\n",
    "**Note that we are NOT making inferences about the population distribution, but only about some population parameter of interest (like the mean).**\n",
    "\n",
    "Let's see what happens when we record the mean and the 95th percentile of each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_samples = []                                                   # Initialize an empty list\n",
    "bootstrap_sample_means = np.zeros(1000)                                  # Initialize an array of means\n",
    "bootstrap_sample_95pcts = np.zeros(1000)                                 # And another of 95th percentiles\n",
    "for i in range(1000):\n",
    "    bootstrap_sample = np.random.choice(sample, size=1000)               # Take 1000 points from one of the dists\n",
    "    bootstrap_samples.append(bootstrap_sample)                           # Add that to the list\n",
    "    bootstrap_sample_means[i] = bootstrap_sample.mean()                  # Add the mean to the means' array\n",
    "    bootstrap_sample_95pct = np.percentile(a=bootstrap_sample, q=95)\n",
    "    bootstrap_sample_95pcts[i] = bootstrap_sample_95pct                  # Add the 95th percentile to the\n",
    "                                                                         # percentiles'array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_95pcts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_sample_means);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bootstrap_sample_95pcts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_means.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_sample_95pcts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(a=pop, q=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Bootstrap?\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) is helpful on this.\n",
    "\n",
    "With a bootstrap we are simulating the relationship between population and sample by treating our sample as the population. In that case we can actually measure the error between our estimates (made through resampling) and the true sample statistics.\n",
    "\n",
    "\"Adèr et al. recommend the bootstrap procedure for the following situations (Adèr, H. J., Mellenbergh G. J., & Hand, D. J. (2008). *Advising on research methods: A consultant's companion*. Huizen, The Netherlands: Johannes van Kessel Publishing. ISBN 978-90-79418-01-5.):\n",
    "\n",
    "- When the theoretical distribution of a statistic of interest is complicated or unknown. Since the bootstrapping procedure is distribution-independent it provides an indirect method to assess the properties of the distribution underlying the sample and the parameters of interest that are derived from this distribution.\n",
    "- When the sample size is insufficient for straightforward statistical inference. If the underlying distribution is well-known, bootstrapping provides a way to account for the distortions caused by the specific sample that may not be fully representative of the population.\n",
    "- When power calculations have to be performed, and a small pilot sample is available. Most power and sample size calculations are heavily dependent on the standard deviation of the statistic of interest. If the estimate used is incorrect, the required sample size will also be wrong. One method to get an impression of the variation of the statistic is to use a small pilot sample and perform bootstrapping on it to get impression of the variance.\"\n",
    "\n",
    "## Bootstrapping Real Data\n",
    "\n",
    "Below we read in a dataset containing information about public toilets in Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin = pd.read_excel('20191101_berlinertoiletten-2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    sample = np.random.choice(berlin['Price'].values, size=len(berlin['Price']))\n",
    "    means.append(np.mean(sample))\n",
    "\n",
    "plt.hist(means);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent could we use these results to draw inferences about public toilet prices in all of Germany? Or all of Europe? Or about past or future toilet prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping Challenge\n",
    "\n",
    "We could use a bootstrap to generate a confidence interval for a hypothesis test.\n",
    "\n",
    "Suppose we had the following two samples of automobile MPG ratings. The question is whether Group 2 (the experimental group) has a significantly higher MPG rating than Group 1 (the control group). Cars in Group 1 have had an average MPG rating around 24.0; we'll count Group 2's average as significantly higher if it's at least 27.5 MPG.\n",
    "\n",
    "We don't have very large samples, but we can use a bootstrap to help!\n",
    "\n",
    "Exercise: Construct 10000 bootstrap samples of the *difference in means* between the two groups. Then order the differences and take the 250th and 9750th values to construct a 95%-confidence interval around our estimate of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the files:\n",
    "\n",
    "grp_1 = pd.read_csv('group1.csv')\n",
    "grp_2 = pd.read_csv('group2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now bootstrap!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
